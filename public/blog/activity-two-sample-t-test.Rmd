---
title: "The two-sample t test"
date: "2019-04-27"
weight: 32
description: "Having already looked at the overlap of confidence intervals on  the means of two groups, formalizing the process as a t-test."
output:
  word_document:
    reference_docx: lesson-style.docx
  html_document:
    rmdformats::material
  pdf_document: tint::tintPdf
categories:
  - activities
tags:
  - t-test
banner: "img/banners/missing.png"
---


```{r include = FALSE}
SDSdata::sds_setup()
library(LittleApp)
library(DT)
t_test_app <- get_app_info("t_test")
```

`r SDSdata::word_pdf_links()`

# Orientation

Suppose you have an explanatory variable that defines two, distinct groups, like the `home_type` variable in the `NHANES2` data. You  notice that the two groups have different mean values for the explanatory variable. 

A possible explanation for the observed difference in the two means is that it is just a pattern that reflects the play of chance rather than any systematic difference in the population of the two groups,

One way to test this explanation is to look at the *confidence intervals* on the means. If they overlap, the just-chance explanation is plausible. If they don't overlap, the *just-chance* explanation isn't plausible. 

The *just-chance* explanation is called the *Null Hypothesis*. 

Testing the Null Hypothesis by looking at the overlap, or lack of  overlap, between the two confidence intervals works very well. But in the early 1900s,  mathematicians and, believe if or not, a brewer at Guinness, discovered a method that is slightly more reliable, especially when the number of data points in each group is small, say < 10. The more reliable method is called a *t test*. 

This lesson introduces the t test.

# Activity

Open up the [t-test](`r t_test_app$url`) Little App. (See footnote^[<`r t_test_app$url`>]). Set the response variable to `income_poverty` and the explanatory variable to `home_type`. Set the sample size to n = 100. Check the box in the controls to show the mean values of the two groups.

1. Check the box in the controls to show the *confidence interval* on the mean and the *t-interval*.  The t-interval is  displayed as a black, sideways-H shape. The t-interval is always *centered* on one of the two means. The t-test is based on whether the other mean falls inside the t-interval or outside.

    * Is the other mean inside or outside the t-interval?
 
2. The t-statistic is simply telling how far apart the two means are  with respect to the t-interval. Go to the "Statistics" tab to see the report from the t-test and read off the t-statistic. When the other mean is right at the boundary of the T-interval, the t statistic is 2. If the mean is farther outside the T interval, the t statistic is proportionately greater than 2. 

    * Look at where the second mean is with respect to the T interval, and compare that to the value of t shown in the report in the Statistics tab. Do they  correspond? Look  at several new samples to  see  whether the correspondence continues to hold.
    
3. The t-statistic is usually translated into a p-value, which is a  probability. The p-value will be less than 0.05 when the other mean is outside the t-interval.

    * Does the p-value  go up or down  with the t-statistic? Look at several new samples to figure out which.

4. Check the "Shuffle groups" box. This simulates a situation where there is no systematic relationship between the response and explanatory variables. 

     * Note whether the t-interval includes both means or, much the same thing, whether the confidence intervals do not overlap. Press New Sample several times to see whether the confidence-interval overlap (or lack of overlap) is consistent from one sample to another.
     
     * Look  at the p-value across several new samples with shuffling on. 
     
     `r question_blank("*Write down the largest p-value you see? What's the smallest? What's a typical p-value?*", breaks = 2)`


----------------------

Version 0.2, `r Sys.Date()`, Carol Howald, 